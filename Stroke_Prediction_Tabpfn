import pandas as pd
import torch
import os
os.environ["TABPFN_ALLOW_CPU_LARGE_DATASET"] = "1"
from sklearn.metrics import precision_recall_curve, average_precision_score, auc
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_recall_fscore_support
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score

from tabpfn import TabPFNClassifier


df = pd.read_csv('/home/rcui/project/stroke_detector/healthcare-dataset-stroke-data.csv')


df = df.replace("N/A", np.nan)

target_col = "stroke"
y = df[target_col].astype(int)
X = df.drop(columns=[target_col])

numeric_cols = ["age", "avg_glucose_level", "bmi"]
binary_int_cols = ["hypertension", "heart_disease"]     
cat_cols = ["gender", "ever_married", "work_type", "Residence_type", "smoking_status"]


numeric_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

binary_transformer = "passthrough"  

categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=False)) 
])

preprocess = ColumnTransformer(
    transformers=[
        ("num", numeric_transformer, numeric_cols),
        ("bin", binary_transformer, binary_int_cols),
        ("cat", categorical_transformer, cat_cols),
    ],
    remainder="drop"
)


X_train_raw, X_test_raw, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)


X_train = preprocess.fit_transform(X_train_raw)
X_test = preprocess.transform(X_test_raw)

max_rows = 1024
if X_train.shape[0] > max_rows:
    rng = np.random.default_rng(42)
    idx = rng.choice(X_train.shape[0], max_rows, replace=False)
    X_train_sub = X_train[idx]
    y_train_sub = y_train.values[idx]
else:
    X_train_sub = X_train
    y_train_sub = y_train.values

clf0 = TabPFNClassifier(device="cpu")
clf0.fit(X_train_sub, y_train_sub)
probs_train = clf0.predict_proba(X_train_sub)[:, 1]


neg_idx = np.where(y_train_sub == 0)[0]
pos_idx = np.where(y_train_sub == 1)[0]


k = len(pos_idx)
hard_neg_idx = neg_idx[np.argsort(probs_train[neg_idx])[-k:]]


weights = np.ones_like(y_train_sub, dtype=int)
weights[hard_neg_idx] = 2   

X_train_weighted = np.repeat(X_train_sub, weights, axis=0)
y_train_weighted = np.repeat(y_train_sub, weights, axis=0)


clf = TabPFNClassifier(device="cpu")
clf.fit(X_train_weighted, y_train_weighted)


y_pred    = clf.predict(X_test)
probs      = clf.predict_proba(X_test)[:, 1]


print("Threshold sweep results:")
thresholds = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3]

best_t = None
best_f1 = -1

print("Threshold sweep results:")
for t in thresholds:
    y_pred_t = (probs > t).astype(int)
    p, r, f1, _ = precision_recall_fscore_support(
        y_test, y_pred_t,
        average="binary",
        zero_division=0
    )
    print(f" t={t:.2f} → Precision={p:.3f}, Recall={r:.3f}, F1={f1:.3f}")
    if f1 > best_f1:
        best_f1 = f1
        best_t = t

print(f"\n→ Best threshold by F1 is {best_t:.2f} (F1={best_f1:.3f})")

y_pred_auto = (probs > best_t).astype(int)
print(f"\nFinal report at threshold = {best_t:.2f}:")

print("Accuracy:", accuracy_score(y_test, y_pred_auto))
print("ROC-AUC:", roc_auc_score(y_test, probs))
print(classification_report(y_test, y_pred_auto, digits=4))


precision, recall, pr_thresholds = precision_recall_curve(y_test, probs)

pr_auc = auc(recall, precision)
print(f"PR AUC: {pr_auc:.4f}")

ap = average_precision_score(y_test, probs)
print(f"Average precision (AP): {ap:.4f}")

baseline = y_test.mean()
print(f"Baseline AP (positive prevalence): {baseline:.4f}")

